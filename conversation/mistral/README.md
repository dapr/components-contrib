# Mistral Conversation Component

This component provides access to Mistral AI models through Dapr's conversation API using LangChain Go.

## Overview

The Mistral component extends the base LangChainGoKit implementation with Mistral-specific enhancements to provide seamless tool calling support while working around Mistral's conversation flow limitations.

## Key Features

### üîß **Automatic Tool Result Conversion**

Mistral has strict conversation flow requirements and cannot process formal tool results for tool calls that weren't originally generated by Mistral in the same conversation session. This component automatically converts tool results to text-based messages that Mistral can handle.

**How it works:**
- When the component receives a `ToolResultContentPart`, it automatically converts it to a text-based user message
- The conversion maintains all the information while presenting it in a format Mistral can process
- This happens transparently - users can send formal tool results and they'll be converted automatically

**Example conversion:**
```
Input: ToolResultContentPart{
  ToolCallID: "call_123",
  Name: "get_weather", 
  Content: "Sunny, 72¬∞F",
  IsError: false
}

Output: TextContentPart{
  Text: "The get_weather function returned: Sunny, 72¬∞F. Please use this information to respond to the user."
}
```

### üõ†Ô∏è **Full Tool Calling Support**

- **Tool Call Generation**: Mistral can generate tool calls when appropriate
- **Parallel Tool Calling**: Supports multiple tool calls in a single response
- **Error Handling**: Properly handles both successful and error tool results
- **Multi-turn Conversations**: Maintains conversation context across multiple turns

### ‚ö° **Performance Optimized**

- **Direct LangChain Integration**: Uses LangChain Go for optimal performance
- **Provider-Compatible Tool Call IDs**: Generates 9-character alphanumeric IDs as required by Mistral
- **Efficient Conversion**: Minimal overhead for tool result processing

## Configuration

### Basic Configuration
```yaml
apiVersion: dapr.io/v1alpha1
kind: Component
metadata:
  name: mistral
spec:
  type: conversation.mistral
  version: v1
  metadata:
    - name: key
      value: "your_mistral_api_key_here"
    - name: model
      value: "open-mistral-7b"  # Default model
```

### Advanced Configuration
```yaml
apiVersion: dapr.io/v1alpha1
kind: Component
metadata:
  name: mistral-advanced
spec:
  type: conversation.mistral
  version: v1
  metadata:
    - name: key
      value: "your_mistral_api_key_here"
    - name: model
      value: "mistral-large-latest"
    - name: cacheTTL
      value: "10m"  # Enable response caching
```

## Supported Models

The component supports all Mistral AI models available through their API:

- **open-mistral-7b** (default) - Fast and efficient for most tasks
- **mistral-small-latest** - Balanced performance and cost
- **mistral-medium-latest** - Enhanced capabilities
- **mistral-large-latest** - Most capable model
- **codestral-latest** - Optimized for code generation

## Tool Calling Examples

### Basic Tool Call
```json
{
  "inputs": [
    {
      "role": "user",
      "parts": [
        {
          "type": "text",
          "text": "What's the weather like in Paris?"
        },
        {
          "type": "tool_definitions",
          "tools": [
            {
              "type": "function",
              "function": {
                "name": "get_weather",
                "description": "Get current weather for a location",
                "parameters": {
                  "type": "object",
                  "properties": {
                    "location": {
                      "type": "string",
                      "description": "City name"
                    }
                  },
                  "required": ["location"]
                }
              }
            }
          ]
        }
      ]
    }
  ]
}
```

### Tool Result Processing (Automatic Conversion)
```json
{
  "inputs": [
    {
      "role": "tool",
      "parts": [
        {
          "type": "tool_result",
          "tool_call_id": "call_abc123",
          "name": "get_weather",
          "content": "Partly cloudy, 18¬∞C in Paris",
          "is_error": false
        }
      ]
    }
  ]
}
```

**Mistral will receive this as:**
```json
{
  "role": "user",
  "parts": [
    {
      "type": "text", 
      "text": "The get_weather function returned: Partly cloudy, 18¬∞C in Paris. Please use this information to respond to the user."
    }
  ]
}
```

## Multi-turn Tool Calling Workflow

1. **User Request**: "What's the weather like and what should I wear?"
2. **Mistral Response**: Generates `get_weather` tool call
3. **Tool Execution**: External system executes the weather API call
4. **Tool Result**: Automatic conversion to text: "The get_weather function returned: Sunny, 75¬∞F"
5. **Mistral Response**: "It's sunny and 75¬∞F. I recommend wearing light clothing like a t-shirt and shorts."

## Error Handling

The component gracefully handles various error scenarios:

### Tool Execution Errors
```json
{
  "type": "tool_result",
  "tool_call_id": "call_xyz789",
  "name": "get_weather",
  "content": "Location not found",
  "is_error": true
}
```

**Converted to:**
```
"The get_weather function returned an error: Location not found. Please use this information to respond to the user."
```

### API Errors
- Invalid API keys
- Rate limiting
- Model unavailability
- Network issues

## Comparison with Other Providers

| Feature | Mistral | OpenAI | Anthropic |
|---------|---------|---------|-----------|
| Tool Call Generation | ‚úÖ | ‚úÖ | ‚úÖ |
| Parallel Tool Calls | ‚úÖ | ‚úÖ | ‚úÖ |
| Formal Tool Results | ‚úÖ (Auto-converted) | ‚úÖ | ‚úÖ |
| Multi-turn Tool Calling | ‚úÖ | ‚úÖ | ‚úÖ |
| Streaming | ‚úÖ | ‚úÖ | ‚úÖ |

## Best Practices

1. **Tool Definitions**: Provide clear, detailed descriptions for better tool selection
2. **Error Handling**: Always handle both successful and error tool results
3. **Conversation Context**: Maintain conversation history for multi-turn interactions
4. **Model Selection**: Choose appropriate model based on complexity and performance needs
5. **Caching**: Use `cacheTTL` for repeated similar requests to improve performance

## Troubleshooting

### Common Issues

**Issue**: "Tool call id has to be defined"
- **Cause**: This was a previous limitation that has been resolved
- **Solution**: Update to the latest version with automatic tool result conversion

**Issue**: Tool calls not being generated
- **Cause**: Unclear tool descriptions or missing required parameters
- **Solution**: Improve tool descriptions and ensure all required parameters are specified

**Issue**: Rate limiting errors
- **Cause**: Exceeding Mistral API rate limits
- **Solution**: Implement exponential backoff and respect rate limits

## Authentication

### API Key Setup
1. Sign up at [Mistral AI](https://mistral.ai/)
2. Generate an API key from your dashboard
3. Set the `MISTRAL_API_KEY` environment variable or configure it in the component metadata

### Environment Variable
```bash
export MISTRAL_API_KEY="your_api_key_here"
```

## Performance Considerations

- **Model Selection**: Larger models provide better capabilities but higher latency
- **Caching**: Enable caching for repeated similar requests
- **Batch Processing**: Group related requests when possible
- **Tool Optimization**: Keep tool descriptions concise but comprehensive

## Limitations

1. **Conversation History**: Mistral requires consistent conversation flow
2. **Tool Call IDs**: Must be exactly 9 alphanumeric characters (handled automatically)
3. **Context Window**: Limited by model's context window size
4. **Rate Limits**: Subject to Mistral API rate limits

## Future Enhancements

- **Streaming Tool Calls**: Support for streaming tool call generation
- **Function Calling Templates**: Pre-built templates for common use cases
- **Enhanced Error Recovery**: Automatic retry with exponential backoff
- **Conversation Persistence**: Built-in conversation state management

---

The Mistral conversation component provides a robust, production-ready solution for integrating Mistral AI models into your Dapr applications with full tool calling support and automatic compatibility handling. 