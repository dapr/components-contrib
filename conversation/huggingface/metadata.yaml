# yaml-language-server: $schema=../../../component-metadata-schema.json
schemaVersion: v1
type: conversation
name: huggingface
version: v1
status: alpha
title: "Huggingface"
urls:
  - title: Reference
    url: https://docs.dapr.io/reference/components-reference/supported-conversation/hugging-face/
authenticationProfiles:
  - title: "API Key"
    description: "Authenticate using an API key"
    metadata:
      - name: key
        type: string
        required: true
        sensitive: true
        description: |
          API key for Huggingface.
        example:  "**********"
        default: ""
metadata:
  - name: model
    required: false
    description: |
      The Huggingface model to use. Uses OpenAI-compatible API. Configurable via HUGGINGFACE_MODEL environment variable.
    type: string
    example: 'deepseek-ai/DeepSeek-R1-Distill-Qwen-32B'
    default: 'deepseek-ai/DeepSeek-R1-Distill-Qwen-32B'
  - name: endpoint
    required: false
    description: |
      Custom OpenAI-compatible endpoint URL for the model. If not specified, automatically generates the endpoint based on the model name using the template: https://router.huggingface.co/hf-inference/models/{{model}}/v1
    type: string
    example: 'https://router.huggingface.co/hf-inference/models/microsoft/DialoGPT-medium/v1'
  - name: cacheTTL
    required: false
    description: |
      A time-to-live value for a prompt cache to expire. Uses Golang durations
    type: string
    example: '10m'
